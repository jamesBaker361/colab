{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "horse.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesBaker361/colab/blob/master/horse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WcEy-_wQG92z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwspu6EeHnVl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/neural-style-transfer-tutorial-part-1-f5cd3315fa7f\n"
      ]
    },
    {
      "metadata": {
        "id": "xV-FlzhbHqnz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "what is vgg?? https://arxiv.org/pdf/1409.1556.pdf\n"
      ]
    },
    {
      "metadata": {
        "id": "_BeC5VFdJa_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "import numpy as np\n",
        "from pylab import rcParams\n",
        "\n",
        "batch=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1y26omARvvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_layer = tf.placeholder('float', shape=(224,224)) #input layer is 224 x 224\n",
        "#input4d=tf.reshape(input_layer,(1,224,224,64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elwBu_wmWxmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filter_layer=tf.placeholder('float',shape=(3,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJZc-YE3e_Ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_1_layer_vals = {\n",
        "'weights':tf.Variable(tf.random_normal([n_nodes_inpl,n_nodes_hl1])),\n",
        "'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTKFmhr7Sa9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_1=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,64)),\n",
        "    tf.placeholder('float',shape=(3,3,64,128)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_1\"\n",
        ")\n",
        "\n",
        "layer_1_mp=tf.nn.max_pool( tf.placeholder('float',shape=(batch,224,224,128)),\n",
        "    (2,2,2,2),\n",
        "    [1,2,2,1],\n",
        "    \"VALID\",name=\"layer_1_mp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUgANvCMmjbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_2=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,128)),\n",
        "    tf.placeholder('float',shape=(3,3,128,256)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_2\"\n",
        ")\n",
        "\n",
        "layer_2_mp=tf.nn.max_pool( tf.placeholder('float',shape=(batch,224,224,256)),\n",
        "    (2,2,2,2),\n",
        "    [1,2,2,1],\n",
        "    \"VALID\",name=\"layer_2_mp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ni27pIFvm0A8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_3=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,256)),\n",
        "    tf.placeholder('float',shape=(3,3,256,256)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_3\"\n",
        ")\n",
        "layer_4=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,256)),\n",
        "    tf.placeholder('float',shape=(3,3,256,512)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_4\"\n",
        ")\n",
        "\n",
        "layer_4_mp=tf.nn.max_pool( tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    (2,2,2,2),\n",
        "    [1,2,2,1],\n",
        "    \"VALID\",name=\"layer_4_mp\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4D_3plTnpNFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_5=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    tf.placeholder('float',shape=(3,3,512,512)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_5\"\n",
        ")\n",
        "\n",
        "layer_6=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    tf.placeholder('float',shape=(3,3,512,512)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_6\"\n",
        ")\n",
        "\n",
        "layer_6_mp=tf.nn.max_pool( tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    (2,2,2,2),\n",
        "    [1,2,2,1],\n",
        "    \"VALID\",name=\"layer_6_mp\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dL_Tie48ppE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_7=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    tf.placeholder('float',shape=(3,3,512,512)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_7\"\n",
        ")\n",
        "\n",
        "layer_8=tf.nn.conv2d(\n",
        "    tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    tf.placeholder('float',shape=(3,3,512,512)),\n",
        "    [1,1,1,1],\n",
        "    \"VALID\",\n",
        "    use_cudnn_on_gpu=True,\n",
        "    data_format='NHWC',\n",
        "    dilations=[1, 1, 1, 1],\n",
        "    name=\"layer_8\"\n",
        ")\n",
        "\n",
        "layer_8_mp=tf.nn.max_pool( tf.placeholder('float',shape=(batch,224,224,512)),\n",
        "    (2,2,2,2),\n",
        "    [1,2,2,1],\n",
        "    \"VALID\",name=\"layer_8_mp\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-y9hwaiqSb5",
        "colab_type": "code",
        "outputId": "9ec9139b-aa97-42f2-ac8c-e3ded5141171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1204
        }
      },
      "cell_type": "code",
      "source": [
        "layer_9=tf.contrib.layers.fully_connected(\n",
        "    tf.placeholder('float',shape=[batch_size, depth], [None, None, None, channels]),\n",
        "    4096)\n",
        "\n",
        "layer_10=tf.contrib.layers.fully_connected(\n",
        "    4096,\n",
        "    4096)\n",
        "\n",
        "layer_11=tf.contrib.layers.fully_connected(\n",
        "    4096,\n",
        "    1000)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7bbe084dab0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m layer_9=tf.contrib.layers.fully_connected(\n\u001b[1;32m      2\u001b[0m     \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     4096)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m layer_10=tf.contrib.layers.fully_connected(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mfully_connected\u001b[0;34m(inputs, num_outputs, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m         _reuse=reuse)\n\u001b[0;32m-> 1855\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \"\"\"\n\u001b[0;32m-> 1227\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     input_spec.assert_input_compatibility(\n\u001b[0;32m-> 1591\u001b[0;31m         self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    137\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer fully_connected is incompatible with the layer: : expected min_ndim=2, found ndim=0. Full shape received: []"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H1vNURE_mQna",
        "colab_type": "code",
        "outputId": "2d21d145-e479-49be-f41e-20accb0b465d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "meansq =    tf.reduce_mean(tf.square(layer_1_mp - output_true))\n",
        "# define our optimizer\n",
        "learn_rate = 0.1   # how fast the model should learn\n",
        "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c459b68a7714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeansq\u001b[0m \u001b[0;34m=\u001b[0m    \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_layer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# define our optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m   \u001b[0;31m# how fast the model should learn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagradOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeansq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_layer' is not defined"
          ]
        }
      ]
    }
  ]
}